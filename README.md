# ğŸš— RAG-Based Vehicle Specification Extraction System

AI-Powered Mechanic Assistant for automatic technical-spec retrieval from vehicle service manuals.

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python)](https://www.python.org/)
[![FAISS](https://img.shields.io/badge/FAISS-Vector%20DB-orange?style=for-the-badge)](https://github.com/facebookresearch/faiss)
[![LangChain](https://img.shields.io/badge/LangChain-RAG-green?style=for-the-badge)](https://github.com/langchain-ai/langchain)
[![Groq](https://img.shields.io/badge/Groq-Llama3.3-ff9900?style=for-the-badge)](https://www.groq.com/)

---

Table of contents
- Overview
- Quick demo
- Features
- How it works (architecture)
- Installation & usage
- Configuration & best practices
- Project structure
- Roadmap
- Contributing
- License & credits

---

## ğŸ“Œ Overview

Mechanics and technicians often need a single number from very long service manuals â€” torque, clearances, fluid capacities, or part numbers. This project automates the retrieval and extraction of those technical specifications using a Retrieval-Augmented Generation (RAG) pipeline:

- PDF ingestion (text + tables)
- Chunking with header injection to retain table context
- Embeddings (SentenceTransformers)
- FAISS vector retrieval
- LLM (Groq Llama 3.3) for strict JSON extraction
- Post-processing & unit normalization

Example user query:
> "What is the torque for the front lower control arm bolt?"

Example JSON output:
```json
{
  "component": "Front Lower Control Arm",
  "spec_type": "Torque",
  "value": 125,
  "unit": "Nm",
  "source": {"pdf": "sample-service-manual.pdf", "page": 142}
}
```

---

## âœ¨ Key Features

- Full RAG stack: FAISS vector DB + instruction-tuned LLM for deterministic extraction
- Strict JSON schema for all outputs (component, spec_type, value, unit, source)
- Table-aware PDF parsing (Camelot / Tabula) + header injection so rows remain meaningful
- Smart unit parsing and normalization (SI â†” Imperial, multi-unit recognition)
- Crash protection: invalid model outputs are detected and fallback extraction attempts are made
- Streamlit-ready frontend and low-memory FAISS setup for quick demos

---

## ğŸ§© Design choices & extraction rules

- Chunk size: 2000 characters, overlap: 300 (RecursiveCharacterTextSplitter)
- Separator priority: ["\n\n", "\n", " ", ""]
- Embeddings: all-MiniLM-L6-v2 (dim = 384)
- Default FAISS index: Flat (L2) for maximum accuracy on small/medium datasets
- LLM inference defaults for structured extraction: temperature 0.0â€“0.2, top_p 0.9â€“0.95

Metadata example for vectors:
```json
{
  "page": 142,
  "chunk_id": "c142_3",
  "source": "sample-service-manual.pdf"
}
```

---

## ğŸ›  How it works (RAG flow)

                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚     PDF Ingestion         â”‚
                  â”‚  (text + tables extract)  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Chunker + Header â”‚
                      â”‚    Injection     â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Embeddings Generator â”‚
                      â”‚  (MiniLM-L6-v2)      â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚     FAISS Index      â”‚
                      â”‚   (Vector Storage)   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   User Query   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Streamlit Frontend  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚     Retriever       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚ Top-k chunks
                                            â–¼
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚ Groq Llama 3.3 (70B)    â”‚
                                â”‚ RAG + JSON Extraction   â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â–¼
                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 â”‚ Post Processing  â”‚
                                 â”‚ Units + Schema   â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚ Final JSON Specificationâ”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

---

## ğŸ’¾ Project structure (simplified)

Rag-Based--Vehicle-Specification-Extraction-System/
- faiss_db_index/             
- sample-service-manual.pdf    
- vehicle_specs.json           
- final.ipynb                  
- README.md
- requirements.txt (recommended)
- .gitignore

---

## âš™ï¸ Installation

1. Clone
```bash
git clone https://github.com/Gani9143/Rag-Based--Vehicle-Specification-Extraction-System.git
cd Rag-Based--Vehicle-Specification-Extraction-System
```

2. Create venv (recommended)
```bash
python -m venv .venv
source .venv/bin/activate    # macOS / Linux
.venv\Scripts\activate       # Windows
```

3. Install dependencies
```bash
pip install -r requirements.txt
```

4. Run the demo notebook
- Open final.ipynb in Jupyter / VS Code and run cells in order.

Optional: Run Streamlit demo (if implemented)
```bash
streamlit run app.py
```

---

## ğŸ”§ Configuration & best practices

- Model & inference:
  - Use deterministic settings (temperature 0â€“0.2) for numeric outputs.
  - Include the JSON Schema in the prompt and provide 2â€“3 few-shot examples of expected JSON.
- Retrieval:
  - For small sets, Flat L2 FAISS is fine. For large corpora consider HNSW / IVF + PQ.
- Chunking:
  - Keep chunk size large enough to include table context. Inject headers into extracted table rows so each chunk is self-describing.
- Post-processing:
  - If the LLM returns invalid JSON, attempt regex-based numeric + unit extraction as a fallback.

Example minimal system prompt (illustrative):
```
You are an extraction assistant. Given retrieved manual fragments and metadata, output exactly one valid JSON object matching:
{ "component": string, "spec_type": string, "value": number, "unit": string, "source": {"pdf": string, "page": number} }
```

---

## ğŸ§ª Examples & expected outputs

Input:
> "What is the torque for the rear suspension arm bolt?"

Output:
```json
{
  "component": "Rear Suspension Arm Bolt",
  "spec_type": "Torque",
  "value": 155,
  "unit": "Nm",
  "source": { "pdf": "sample-service-manual.pdf", "page": 118 }
}
```

Unit parsing examples handled:
- "17 Nm (12.6 lb-ft) / 150 lb-in" â†’ capture both primary and converted units when present and normalize.

---

## ğŸ”® Roadmap

- Table-aware chunking â€” Complete
- Camelot-first pipeline â€” In progress
- Hybrid search (BM25 + FAISS) â€” Planned
- Full Streamlit UI â€” Planned
- Vision-based spec extraction (images/diagrams) â€” Backlog
- FastAPI backend for batch extraction â€” Planned

---

## ğŸ¤ Contributing

Contributions welcome! Please:
- Open issues for bugs/feature requests
- Send PRs with clear descriptions and tests where possible
- Follow the project's code style and add documentation for new features

---

## ğŸ“„ License

MIT License â€” see LICENSE file.

---

## â¤ï¸ Credits

- HuggingFace Transformers
- FAISS (Meta AI)
- Sentence Transformers
- LangChain
- Groq Llama 3.3 (model provider)
