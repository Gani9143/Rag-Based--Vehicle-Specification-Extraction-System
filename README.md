# ğŸš— RAG-Based Vehicle Specification Extraction System
_ AI-Powered Mechanic Assistant for Automatic Spec Retrieval_

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python)
![FAISS](https://img.shields.io/badge/FAISS-Vector%20DB-orange?style=for-the-badge)
![LangChain](https://img.shields.io/badge/LangChain-RAG-green?style=for-the-badge)
![Groq](https://img.shields.io/badge/Groq-Llama3.3-ff9900?style=for-the-badge)

---

## ğŸ“Œ Overview
Modern automotive service manuals are hundreds of pages long, making it time-consuming for mechanics to find torque values, fluid quantities, bolt specs, alignment angles, or part numbers.

**RAG-Based Vehicle Specification Extraction System** automates this task. It uses a Retrieval-Augmented Generation pipeline (FAISS + LLM) to retrieve the most relevant manual chunks and extract technical specifications accurately.

**Example user query:**  
> â€œWhat is the torque for the front lower control arm bolt?â€

**Example JSON output:**
```json
{
  "component": "Front Lower Control Arm",
  "spec_type": "Torque",
  "value": 125,
  "unit": "Nm",
  "source": {"pdf": "sample-service-manual.pdf", "page": 142}
}
```

Key Features
ğŸ” 1. Full RAG Architecture

Uses FAISS vector search + Groq Llama 3.3 LLM to retrieve the most relevant manual chunks and extract technical specifications accurately.

ğŸ§© 2. Strict JSON Schema Output

All outputs follow a strict structure:

Component | Spec Type | Value | Unit | Source (PDF + Page)

ğŸ“ 3. Smart Unit Parsing

Automatically detects and splits compound units such as:

17 Nm (12.6 lb-ft) / 150 lb-in

Supports SI and Imperial units.

ğŸ§  4. Context-Aware Table Extraction

âœ” Extracts tables using Camelot/Tabula  
âœ” Converts table data into JSON  
âœ” Injects headers into every row so chunking never loses meaning

Header Injection Example

Raw:

| Bolt | 17 |

Injected:

Component: Bolt | Spec: Torque | Value: 17 Nm

ğŸ§± 5. Chunking Strategy Optimized for Manuals

Chunk size: 2000 characters  
Overlap: 300 characters  
Separator priority:

["\n\n", "\n", " ", ""]

Keeps paragraphs and tables intact for better retrieval accuracy.

ğŸ›¡ï¸ 6. Crash Protection

If LLM returns unstructured/free text:

System detects invalid JSON  
Attempts to extract numbers and units  
Returns fallback readable results

â˜ï¸ 7. Streamlit Deployment Ready

Designed for Streamlit Cloud:

Low memory usage

Fast FAISS retrieval

Clean UI output

ğŸ§  Technical Deep Dive
ğŸ“„ 1. PDF Ingestion Pipeline

Performs:

PDF text extraction

Table extraction

Header injection

Page-level metadata tagging

ğŸ§© 2. Chunking Strategy Table
Property	Value
Chunk size	2000 chars
Overlap	300 chars
Algorithm	RecursiveCharacterTextSplitter
Goal	Preserve table + paragraph context

ğŸ§¬ 3. Embeddings

Model: all-MiniLM-L6-v2

Dimensionality: 384

Metadata example:

{
  "page": 142,
  "chunk_id": "c142_3",
  "source": "sample-service-manual.pdf"
}

ğŸ§± Vector Database â€“ FAISS
Default: Flat L2

Max accuracy

Suitable for small/medium datasets

Advanced Options
Index	Purpose
HNSW	Large dataset, 10x faster search
IVF	Clustering for scalable vector search
PQ	High compression for large manuals

ğŸ—ï¸ System Architecture (RAG Flow)
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚     PDF Ingestion         â”‚
                  â”‚  (text + tables extract)  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Chunker + Header â”‚
                      â”‚    Injection     â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Embeddings Generator â”‚
                      â”‚  (MiniLM-L6-v2)      â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚     FAISS Index      â”‚
                      â”‚   (Vector Storage)   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   User Query   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Streamlit Frontend  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚     Retriever       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚ Top-k chunks
                                            â–¼
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚ Groq Llama 3.3 (70B)    â”‚
                                â”‚ RAG + JSON Extraction   â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â–¼
                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 â”‚ Post Processing  â”‚
                                 â”‚ Units + Schema   â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚ Final JSON Specificationâ”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ› ï¸ Tech Stack
Component	Technology
Frontend	Streamlit
LLM	Groq Llama 3.3
Embeddings	Sentence Transformers
Vector DB	FAISS
PDF Parsing	Camelot / PyPDF2
RAG Pipeline	LangChain
Validation	Pydantic / JSON Schema

## Groq Llama 3.3 â€” Model details & recommended usage
This project uses Groq's distribution of Llama 3.3 (instruction-tuned). Below are practical details and best practices to get predictable, schema-conformant outputs when running the RAG + extraction pipeline.

- Model
  - Name: Groq Llama 3.3 (instruction-tuned)
  - Typical release size referenced in this repo: 70B parameters (check the provider for exact artifact names)
- Access & Licensing
  - Groq/Meta models may have specific access and license terms. Make sure you have the appropriate rights to download or run the model in your environment. If using a hosted offering (Groq Cloud or other providers), follow their usage terms.
- Deployment & Hardware
  - 70B-class models typically require high-memory accelerators for full-precision inference. Options:
    - Hosted inference (recommended for most users): Groq Cloud or other inference providers.
    - Local inference: Use quantized weights (4-bit/8-bit) and a large-memory GPU/accelerator. Hardware requirements vary by quantization and runtime â€” verify with your chosen runtime.
- Inference Settings (recommended defaults for structured extraction)
  - temperature: 0.0 â€” 0.2 (lower is better for deterministic, numeric outputs)
  - top_p: 0.9 â€” 0.95
  - max_tokens: 256 â€” 1024 (depending on the expected JSON payload)
  - repetition_penalty: 1.0
  - batch size: keep small for stable outputs
- Prompting & Safety
  - Use a strict system prompt that instructs the model to output only valid JSON conforming to the schema (no extra commentary).
  - Include the JSON Schema in the prompt or as part of the system instruction to improve compliance.
  - If the model returns invalid JSON, use the project's built-in post-processing / crash protection to extract numbers/units and build fallback responses.
- Example System Prompt (short)
```text
You are a technical extraction assistant. Given the retrieved manual text fragments and page metadata, output exactly one valid JSON object that matches this schema: { "component": string, "spec_type": string, "value": number, "unit": string, "source": { "pdf": string, "page": integer } }. Do NOT output any explanation, markdown, or extra fields. If unsure, output null for missing fields.
```

ğŸ§ª Prompt engineering tips
- Provide the model with top-k relevant chunks + explicit examples of desired JSON outputs.
- Use few-shot examples (2â€“3) in the prompt showing exact JSON the system should return.
- Force deterministic settings (temperature near 0) for numeric extraction tasks.

ğŸ“‚ Project Structure
Rag-Based--Vehicle-Specification-Extraction-System/
â”‚
â”œâ”€â”€ faiss_db_index/             
â”œâ”€â”€ sample-service-manual.pdf    
â”œâ”€â”€ vehicle_specs.json           
â”œâ”€â”€ final.ipynb                  
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

âš™ï¸ Installation
Clone the Repository
git clone https://github.com/<user>/Rag-Based--Vehicle-Specification-Extraction-System.git
cd Rag-Based--Vehicle-Specification-Extraction-System

Install Dependencies
pip install -r requirements.txt

Run Notebook

Open and run:

final.ipynb

ğŸ“˜ Sample Query & Output
Input

â€œWhat is the torque for the rear suspension arm bolt?â€

Output
{
  "component": "Rear Suspension Arm Bolt",
  "spec_type": "Torque",
  "value": 155,
  "unit": "Nm",
  "source": {
    "pdf": "sample-service-manual.pdf",
    "page": 118
  }
}

ğŸ”® Future Roadmap
Feature	Priority	Status
Table-Aware Chunking	â­â­â­â­â­	Complete
Hybrid Search (BM25 + FAISS)	â­â­â­â­	Planned
Vision-Based Spec Extraction	â­â­â­	Backlog
Full Streamlit UI	â­â­â­â­	Planned
FastAPI Backend	â­â­â­	Planned
Camelot-First Pipeline	â­â­â­â­â­	In Progress

ğŸ¤ Contributing

Pull requests are welcome!

ğŸ“„ License

MIT License

â¤ï¸ Credits

HuggingFace Transformers

FAISS (Meta AI)

Sentence Transformers

LangChain

Groq Llama 3.3
